{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucessfully got the file TheVerdict.txt\n",
      "This file has 20479 characters\n"
     ]
    }
   ],
   "source": [
    "filePath = \"TheVerdict.txt\"\n",
    "try:\n",
    "    with open(filePath, 'r', encoding=\"utf-8\") as file:\n",
    "        rawText = file.read()\n",
    "        print(f\"sucessfully got the file {filePath}\\nThis file has {len(rawText)} characters\")\n",
    "except:\n",
    "    print(\"Error getting the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius--though', 'a', 'good', 'fellow', 'enough--so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that,', 'in', 'the', 'height', 'of', 'his', 'glory,', 'he', 'had', 'dropped', 'his', 'painting,', 'married', 'a', 'rich', 'widow,', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera.', '(Though', 'I']\n"
     ]
    }
   ],
   "source": [
    "#Space only Tokenizer\n",
    "SpaceTokenizedText = re.split(\"\\s\", rawText)\n",
    "# \"\\s\" is used and r\"(\\s)\" is used as this will make an item for the white space also ' '\n",
    "# This is further talked about in my notes under \"2.2 Tokenizing Text\"\n",
    "print(SpaceTokenizedText[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself']\n"
     ]
    }
   ],
   "source": [
    "# Space and punctuation Tokenizer\n",
    "SpacePuncTokenizedText = re.findall(r'\\w+|[,.:;?_!\"()\\']|--', rawText)\n",
    "print(SpacePuncTokenizedText[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 1148\n",
      "{'!': 0, '\"': 1, \"'\": 2, '(': 3, ')': 4, ',': 5, '--': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'Ah': 12, 'Among': 13, 'And': 14, 'Are': 15, 'Arrt': 16, 'As': 17, 'At': 18, 'Be': 19, 'Begin': 20, 'Burlington': 21, 'But': 22, 'By': 23, 'Carlo': 24, 'Chicago': 25, 'Claude': 26, 'Come': 27, 'Croft': 28, 'Destroyed': 29, 'Devonshire': 30, 'Don': 31, 'Dubarry_': 32, 'Emperors': 33, 'Florence': 34, 'For': 35, 'Gallery': 36, 'Gideon': 37, 'Gisburn': 38, 'Gisburns': 39, 'Grafton': 40, 'Greek': 41, 'Grindle': 42, 'Grindles': 43, 'HAD': 44, 'Had': 45, 'Hang': 46, 'Has': 47, 'He': 48, 'Her': 49, 'Hermia': 50, 'His': 51, 'How': 52, 'I': 53, 'If': 54, 'In': 55, 'It': 56, 'Jack': 57, 'Jove': 58, 'Just': 59, 'Lord': 60, 'Made': 61, 'Miss': 62, 'Money': 63, 'Monte': 64, 'Moon': 65, 'Mr': 66, 'Mrs': 67, 'My': 68, 'Never': 69, 'No': 70, 'Now': 71, 'Nutley': 72, 'Of': 73, 'Oh': 74, 'On': 75, 'Once': 76, 'Only': 77, 'Or': 78, 'Perhaps': 79, 'Poor': 80, 'Professional': 81, 'Renaissance': 82, 'Rickham': 83, 'Riviera': 84, 'Rome': 85, 'Russian': 86, 'Sevres': 87, 'She': 88, 'Stroud': 89, 'Strouds': 90, 'Suddenly': 91, 'That': 92, 'The': 93, 'Then': 94, 'There': 95, 'They': 96, 'This': 97, 'Those': 98, 'Though': 99, 'Thwing': 100, 'Thwings': 101, 'To': 102, 'Usually': 103, 'Venetian': 104, 'Victor': 105, 'Was': 106, 'We': 107, 'Well': 108, 'What': 109, 'When': 110, 'Why': 111, 'Yes': 112, 'You': 113, '_I': 114, '_am_': 115, '_famille': 116, '_felt_': 117, '_has_': 118, '_have_': 119, '_jardiniere_': 120, '_mine_': 121, '_not_': 122, '_rose': 123, '_rs_': 124, '_that_': 125, '_the_': 126, '_was_': 127, '_were_': 128, 'a': 129, 'abdication': 130, 'able': 131, 'about': 132, 'above': 133, 'abruptly': 134, 'absolute': 135, 'absorbed': 136, 'absurdity': 137, 'academic': 138, 'accuse': 139, 'accustomed': 140, 'across': 141, 'activity': 142, 'add': 143, 'added': 144, 'admirers': 145, 'adopted': 146, 'adulation': 147, 'advance': 148, 'aesthetic': 149, 'affect': 150, 'afraid': 151, 'after': 152, 'afterward': 153, 'again': 154, 'ago': 155, 'ah': 156, 'air': 157, 'alive': 158, 'all': 159, 'almost': 160, 'alone': 161, 'along': 162, 'always': 163, 'amazement': 164, 'amid': 165, 'among': 166, 'amplest': 167, 'amusing': 168, 'an': 169, 'and': 170, 'another': 171, 'answer': 172, 'answered': 173, 'any': 174, 'anything': 175, 'anywhere': 176, 'apparent': 177, 'apparently': 178, 'appearance': 179, 'appeared': 180, 'appointed': 181, 'are': 182, 'arm': 183, 'arms': 184, 'art': 185, 'articles': 186, 'artist': 187, 'as': 188, 'aside': 189, 'asked': 190, 'at': 191, 'atmosphere': 192, 'atom': 193, 'attack': 194, 'attention': 195, 'attitude': 196, 'audacities': 197, 'away': 198, 'awful': 199, 'axioms': 200, 'azaleas': 201, 'back': 202, 'background': 203, 'balance': 204, 'balancing': 205, 'balustraded': 206, 'basking': 207, 'bath': 208, 'be': 209, 'beaming': 210, 'bean': 211, 'bear': 212, 'beard': 213, 'beauty': 214, 'became': 215, 'because': 216, 'becoming': 217, 'bed': 218, 'been': 219, 'before': 220, 'began': 221, 'begun': 222, 'behind': 223, 'being': 224, 'believed': 225, 'beneath': 226, 'bespoke': 227, 'better': 228, 'between': 229, 'big': 230, 'bits': 231, 'bitterness': 232, 'blocked': 233, 'born': 234, 'borne': 235, 'boudoir': 236, 'brac': 237, 'bravura': 238, 'break': 239, 'breaking': 240, 'breathing': 241, 'breeding': 242, 'bric': 243, 'briefly': 244, 'brings': 245, 'bronzes': 246, 'brought': 247, 'brown': 248, 'brush': 249, 'bull': 250, 'business': 251, 'but': 252, 'buying': 253, 'by': 254, 'called': 255, 'came': 256, 'can': 257, 'canvas': 258, 'canvases': 259, 'cards': 260, 'care': 261, 'career': 262, 'caught': 263, 'central': 264, 'century': 265, 'chair': 266, 'chairs': 267, 'chap': 268, 'characteristic': 269, 'charming': 270, 'cheap': 271, 'check': 272, 'cheeks': 273, 'chest': 274, 'chimney': 275, 'chucked': 276, 'cigar': 277, 'cigarette': 278, 'cigars': 279, 'circulation': 280, 'circumstance': 281, 'circus': 282, 'claimed': 283, 'clasping': 284, 'clear': 285, 'cleverer': 286, 'close': 287, 'closets': 288, 'clown': 289, 'clue': 290, 'coat': 291, 'collapsed': 292, 'colour': 293, 'come': 294, 'comfortable': 295, 'coming': 296, 'companion': 297, 'compared': 298, 'complex': 299, 'confident': 300, 'congesting': 301, 'conjugal': 302, 'constraint': 303, 'consummate': 304, 'contended': 305, 'continued': 306, 'corner': 307, 'corrected': 308, 'cotta': 309, 'could': 310, 'couldn': 311, 'count': 312, 'countenance': 313, 'couple': 314, 'course': 315, 'covered': 316, 'craft': 317, 'cried': 318, 'crossed': 319, 'crowned': 320, 'crumbled': 321, 'cry': 322, 'cured': 323, 'curiosity': 324, 'curious': 325, 'current': 326, 'curtains': 327, 'd': 328, 'dabble': 329, 'damask': 330, 'dancers': 331, 'dark': 332, 'dashed': 333, 'day': 334, 'days': 335, 'dead': 336, 'deadening': 337, 'dear': 338, 'deep': 339, 'deerhound': 340, 'degree': 341, 'delicate': 342, 'demand': 343, 'denied': 344, 'deploring': 345, 'deprecating': 346, 'deprecatingly': 347, 'desire': 348, 'destroyed': 349, 'destruction': 350, 'desultory': 351, 'detail': 352, 'diagnosis': 353, 'did': 354, 'didn': 355, 'died': 356, 'dim': 357, 'dimmest': 358, 'dingy': 359, 'dining': 360, 'disarming': 361, 'discovery': 362, 'discrimination': 363, 'discussion': 364, 'disdain': 365, 'disdained': 366, 'disease': 367, 'disguised': 368, 'display': 369, 'dissatisfied': 370, 'distinguished': 371, 'distract': 372, 'divert': 373, 'do': 374, 'doesn': 375, 'doing': 376, 'domestic': 377, 'don': 378, 'done': 379, 'donkey': 380, 'down': 381, 'dozen': 382, 'dragged': 383, 'drawing': 384, 'drawn': 385, 'dress': 386, 'drew': 387, 'dropped': 388, 'each': 389, 'earth': 390, 'ease': 391, 'easel': 392, 'easy': 393, 'echoed': 394, 'economy': 395, 'effect': 396, 'effects': 397, 'efforts': 398, 'egregious': 399, 'eighteenth': 400, 'elbow': 401, 'elegant': 402, 'else': 403, 'embarrassed': 404, 'enabled': 405, 'end': 406, 'endless': 407, 'enjoy': 408, 'enlightenment': 409, 'enough': 410, 'ensuing': 411, 'equally': 412, 'equanimity': 413, 'escape': 414, 'established': 415, 'etching': 416, 'even': 417, 'event': 418, 'ever': 419, 'everlasting': 420, 'every': 421, 'exasperated': 422, 'except': 423, 'excuse': 424, 'excusing': 425, 'existed': 426, 'expected': 427, 'exquisite': 428, 'exquisitely': 429, 'extenuation': 430, 'exterminating': 431, 'extracting': 432, 'eye': 433, 'eyebrows': 434, 'eyes': 435, 'face': 436, 'faces': 437, 'fact': 438, 'faded': 439, 'failed': 440, 'failure': 441, 'fair': 442, 'faith': 443, 'false': 444, 'familiar': 445, 'fancy': 446, 'fashionable': 447, 'fate': 448, 'feather': 449, 'feet': 450, 'fell': 451, 'fellow': 452, 'felt': 453, 'few': 454, 'fewer': 455, 'finality': 456, 'find': 457, 'fingers': 458, 'first': 459, 'fit': 460, 'fitting': 461, 'five': 462, 'flash': 463, 'flashed': 464, 'florid': 465, 'flowers': 466, 'fluently': 467, 'flung': 468, 'follow': 469, 'followed': 470, 'fond': 471, 'footstep': 472, 'for': 473, 'forced': 474, 'forcing': 475, 'forehead': 476, 'foreign': 477, 'foreseen': 478, 'forgive': 479, 'forgotten': 480, 'form': 481, 'formed': 482, 'forming': 483, 'forward': 484, 'fostered': 485, 'found': 486, 'foundations': 487, 'four': 488, 'fragment': 489, 'fragments': 490, 'frame': 491, 'frames': 492, 'frequently': 493, 'friend': 494, 'from': 495, 'full': 496, 'fullest': 497, 'furiously': 498, 'furrowed': 499, 'garlanded': 500, 'garlands': 501, 'gave': 502, 'genial': 503, 'genius': 504, 'gesture': 505, 'get': 506, 'getting': 507, 'give': 508, 'given': 509, 'glad': 510, 'glanced': 511, 'glimpse': 512, 'gloried': 513, 'glory': 514, 'go': 515, 'going': 516, 'gone': 517, 'good': 518, 'got': 519, 'grace': 520, 'gradually': 521, 'gray': 522, 'grayish': 523, 'great': 524, 'greatest': 525, 'greatness': 526, 'grew': 527, 'groping': 528, 'growing': 529, 'had': 530, 'hadn': 531, 'hair': 532, 'half': 533, 'hall': 534, 'hand': 535, 'hands': 536, 'handsome': 537, 'hanging': 538, 'happen': 539, 'happened': 540, 'hard': 541, 'hardly': 542, 'have': 543, 'haven': 544, 'having': 545, 'he': 546, 'head': 547, 'hear': 548, 'heard': 549, 'heart': 550, 'height': 551, 'her': 552, 'here': 553, 'hermit': 554, 'herself': 555, 'hesitations': 556, 'hide': 557, 'high': 558, 'him': 559, 'himself': 560, 'hint': 561, 'his': 562, 'history': 563, 'holding': 564, 'home': 565, 'honour': 566, 'hooded': 567, 'hostess': 568, 'hot': 569, 'hour': 570, 'hours': 571, 'house': 572, 'how': 573, 'humoured': 574, 'hung': 575, 'husband': 576, 'idea': 577, 'idle': 578, 'idling': 579, 'if': 580, 'immediately': 581, 'in': 582, 'incense': 583, 'indifferent': 584, 'inevitable': 585, 'inevitably': 586, 'inflexible': 587, 'insensible': 588, 'insignificant': 589, 'instinctively': 590, 'instructive': 591, 'interesting': 592, 'into': 593, 'ironic': 594, 'irony': 595, 'irrelevance': 596, 'irrevocable': 597, 'is': 598, 'it': 599, 'its': 600, 'itself': 601, 'jealousy': 602, 'just': 603, 'keep': 604, 'kept': 605, 'kind': 606, 'knees': 607, 'knew': 608, 'know': 609, 'known_': 610, 'laid': 611, 'lair': 612, 'landing': 613, 'language': 614, 'last': 615, 'late': 616, 'later': 617, 'latter': 618, 'laugh': 619, 'laughed': 620, 'lay': 621, 'leading': 622, 'lean': 623, 'learned': 624, 'least': 625, 'leathery': 626, 'leave': 627, 'led': 628, 'left': 629, 'leisure': 630, 'lends': 631, 'lent': 632, 'let': 633, 'lies': 634, 'life': 635, 'lift': 636, 'lifted': 637, 'light': 638, 'lightly': 639, 'like': 640, 'liked': 641, 'likeness': 642, 'line': 643, 'lines': 644, 'lingered': 645, 'lips': 646, 'lit': 647, 'little': 648, 'live': 649, 'll': 650, 'loathing': 651, 'long': 652, 'longed': 653, 'longer': 654, 'look': 655, 'looked': 656, 'looking': 657, 'lose': 658, 'loss': 659, 'lounging': 660, 'lovely': 661, 'lucky': 662, 'lump': 663, 'luncheon': 664, 'luxury': 665, 'lying': 666, 'made': 667, 'make': 668, 'man': 669, 'manage': 670, 'managed': 671, 'mantel': 672, 'marble': 673, 'married': 674, 'may': 675, 'me': 676, 'meant': 677, 'mechanically': 678, 'mediocrity': 679, 'medium': 680, 'mentioned': 681, 'mere': 682, 'merely': 683, 'met': 684, 'might': 685, 'mighty': 686, 'millionaire': 687, 'mine': 688, 'minute': 689, 'minutes': 690, 'mirrors': 691, 'modest': 692, 'modesty': 693, 'moment': 694, 'money': 695, 'monumental': 696, 'mood': 697, 'morbidly': 698, 'more': 699, 'most': 700, 'mourn': 701, 'mourned': 702, 'moustache': 703, 'moved': 704, 'much': 705, 'muddling': 706, 'multiplied': 707, 'murmur': 708, 'muscles': 709, 'must': 710, 'my': 711, 'myself': 712, 'mysterious': 713, 'naive': 714, 'near': 715, 'nearly': 716, 'negatived': 717, 'nervous': 718, 'nervousness': 719, 'neutral': 720, 'never': 721, 'next': 722, 'no': 723, 'none': 724, 'not': 725, 'note': 726, 'nothing': 727, 'now': 728, 'nymphs': 729, 'oak': 730, 'obituary': 731, 'object': 732, 'objects': 733, 'occurred': 734, 'oddly': 735, 'of': 736, 'off': 737, 'often': 738, 'oh': 739, 'old': 740, 'on': 741, 'once': 742, 'one': 743, 'ones': 744, 'only': 745, 'onto': 746, 'open': 747, 'or': 748, 'other': 749, 'our': 750, 'ourselves': 751, 'out': 752, 'outline': 753, 'oval': 754, 'over': 755, 'own': 756, 'packed': 757, 'paid': 758, 'paint': 759, 'painted': 760, 'painter': 761, 'painting': 762, 'pale': 763, 'paled': 764, 'palm': 765, 'panel': 766, 'panelled': 767, 'panelling': 768, 'pardonable': 769, 'pardoned': 770, 'part': 771, 'passages': 772, 'passing': 773, 'past': 774, 'pastels': 775, 'pathos': 776, 'patient': 777, 'people': 778, 'perceptible': 779, 'perfect': 780, 'persistence': 781, 'persuasively': 782, 'phrase': 783, 'picture': 784, 'pictures': 785, 'piece': 786, 'pines': 787, 'pink': 788, 'place': 789, 'placed': 790, 'plain': 791, 'platitudes': 792, 'pleased': 793, 'pockets': 794, 'point': 795, 'poised': 796, 'poor': 797, 'portrait': 798, 'posing': 799, 'possessed': 800, 'poverty': 801, 'predicted': 802, 'preliminary': 803, 'presenting': 804, 'presses': 805, 'prestidigitation': 806, 'pretty': 807, 'previous': 808, 'price': 809, 'pride': 810, 'princely': 811, 'prism': 812, 'problem': 813, 'proclaiming': 814, 'prodigious': 815, 'profusion': 816, 'protest': 817, 'prove': 818, 'public': 819, 'purblind': 820, 'purely': 821, 'pushed': 822, 'put': 823, 'qualities': 824, 'quality': 825, 'queerly': 826, 'question': 827, 'quickly': 828, 'quietly': 829, 'quite': 830, 'quote': 831, 'rain': 832, 'raised': 833, 'random': 834, 'rather': 835, 're': 836, 'real': 837, 'really': 838, 'reared': 839, 'reason': 840, 'reassurance': 841, 'recovering': 842, 'recreated': 843, 'reflected': 844, 'reflection': 845, 'regrets': 846, 'relatively': 847, 'remained': 848, 'remember': 849, 'reminded': 850, 'repeating': 851, 'represented': 852, 'reproduction': 853, 'resented': 854, 'resolve': 855, 'resources': 856, 'rest': 857, 'rich': 858, 'ridiculous': 859, 'robbed': 860, 'romantic': 861, 'room': 862, 'rooms': 863, 'rose': 864, 'rule': 865, 'run': 866, 's': 867, 'said': 868, 'same': 869, 'satisfaction': 870, 'savour': 871, 'saw': 872, 'say': 873, 'saying': 874, 'says': 875, 'scorn': 876, 'scornful': 877, 'secret': 878, 'see': 879, 'seemed': 880, 'seen': 881, 'self': 882, 'send': 883, 'sensation': 884, 'sensitive': 885, 'sent': 886, 'serious': 887, 'set': 888, 'sex': 889, 'shade': 890, 'shaking': 891, 'shall': 892, 'she': 893, 'shirked': 894, 'short': 895, 'should': 896, 'shoulder': 897, 'shoulders': 898, 'show': 899, 'showed': 900, 'showy': 901, 'shrug': 902, 'shrugged': 903, 'sight': 904, 'sign': 905, 'silent': 906, 'silver': 907, 'similar': 908, 'simpleton': 909, 'simplifications': 910, 'simply': 911, 'since': 912, 'single': 913, 'sitter': 914, 'sitters': 915, 'sketch': 916, 'skill': 917, 'slight': 918, 'slightly': 919, 'slowly': 920, 'small': 921, 'smile': 922, 'smiling': 923, 'sneer': 924, 'so': 925, 'solace': 926, 'some': 927, 'somebody': 928, 'something': 929, 'spacious': 930, 'spaniel': 931, 'speaking': 932, 'speculations': 933, 'spite': 934, 'splash': 935, 'square': 936, 'stairs': 937, 'stalk': 938, 'stammer': 939, 'stand': 940, 'standing': 941, 'started': 942, 'stay': 943, 'still': 944, 'stocked': 945, 'stood': 946, 'stopped': 947, 'stopping': 948, 'straddling': 949, 'straight': 950, 'strain': 951, 'straining': 952, 'strange': 953, 'straw': 954, 'stream': 955, 'stroke': 956, 'strokes': 957, 'strolled': 958, 'strongest': 959, 'strongly': 960, 'struck': 961, 'studio': 962, 'stuff': 963, 'subject': 964, 'substantial': 965, 'suburban': 966, 'such': 967, 'suddenly': 968, 'suffered': 969, 'sugar': 970, 'suggested': 971, 'sunburn': 972, 'sunburnt': 973, 'sunlit': 974, 'superb': 975, 'sure': 976, 'surest': 977, 'surface': 978, 'surprise': 979, 'surprised': 980, 'surrounded': 981, 'suspected': 982, 'sweetly': 983, 'sweetness': 984, 'swelling': 985, 'swept': 986, 'swum': 987, 't': 988, 'table': 989, 'take': 990, 'taken': 991, 'talking': 992, 'tea': 993, 'tears': 994, 'technicalities': 995, 'technique': 996, 'tell': 997, 'tells': 998, 'tempting': 999, 'terra': 1000, 'terrace': 1001, 'terraces': 1002, 'terribly': 1003, 'than': 1004, 'that': 1005, 'the': 1006, 'their': 1007, 'them': 1008, 'then': 1009, 'there': 1010, 'therefore': 1011, 'they': 1012, 'thin': 1013, 'thing': 1014, 'things': 1015, 'think': 1016, 'this': 1017, 'thither': 1018, 'those': 1019, 'though': 1020, 'thought': 1021, 'three': 1022, 'threshold': 1023, 'threw': 1024, 'through': 1025, 'throwing': 1026, 'tie': 1027, 'till': 1028, 'time': 1029, 'timorously': 1030, 'tinge': 1031, 'tips': 1032, 'tired': 1033, 'to': 1034, 'told': 1035, 'tone': 1036, 'tones': 1037, 'too': 1038, 'took': 1039, 'tottering': 1040, 'touched': 1041, 'toward': 1042, 'trace': 1043, 'trade': 1044, 'transmute': 1045, 'traps': 1046, 'travelled': 1047, 'trees': 1048, 'tribute': 1049, 'tributes': 1050, 'tricks': 1051, 'tried': 1052, 'trouser': 1053, 'true': 1054, 'truth': 1055, 'tubes': 1056, 'turned': 1057, 'twenty': 1058, 'twice': 1059, 'twirling': 1060, 'unaccountable': 1061, 'uncertain': 1062, 'under': 1063, 'underlay': 1064, 'underneath': 1065, 'understand': 1066, 'unexpected': 1067, 'untouched': 1068, 'unusual': 1069, 'up': 1070, 'upon': 1071, 'upset': 1072, 'upstairs': 1073, 'us': 1074, 'used': 1075, 'usual': 1076, 'value': 1077, 'varnishing': 1078, 'vases': 1079, 've': 1080, 'veins': 1081, 'velveteen': 1082, 'verte_': 1083, 'very': 1084, 'villa': 1085, 'vindicated': 1086, 'virtuosity': 1087, 'vista': 1088, 'vocation': 1089, 'voice': 1090, 'wall': 1091, 'wander': 1092, 'want': 1093, 'wanted': 1094, 'wants': 1095, 'was': 1096, 'wasn': 1097, 'watched': 1098, 'watching': 1099, 'water': 1100, 'waves': 1101, 'way': 1102, 'weekly': 1103, 'weeks': 1104, 'welcome': 1105, 'went': 1106, 'were': 1107, 'what': 1108, 'when': 1109, 'whenever': 1110, 'where': 1111, 'which': 1112, 'while': 1113, 'white': 1114, 'who': 1115, 'whole': 1116, 'whom': 1117, 'why': 1118, 'wide': 1119, 'widow': 1120, 'wife': 1121, 'wild': 1122, 'wincing': 1123, 'window': 1124, 'wish': 1125, 'with': 1126, 'without': 1127, 'wits': 1128, 'woman': 1129, 'women': 1130, 'won': 1131, 'wonder': 1132, 'wondered': 1133, 'word': 1134, 'work': 1135, 'working': 1136, 'worth': 1137, 'would': 1138, 'wouldn': 1139, 'year': 1140, 'years': 1141, 'yellow': 1142, 'yet': 1143, 'you': 1144, 'younger': 1145, 'your': 1146, 'yourself': 1147}\n"
     ]
    }
   ],
   "source": [
    "# Making a vocabulary\n",
    "allWords = sorted(set(SpacePuncTokenizedText))\n",
    "vocabSize = len(allWords)\n",
    "print(f\"vocab size: {vocabSize}\")\n",
    "\n",
    "vocab = {word: word_index for word_index, word in enumerate(allWords)}\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.inverseVocab = {word_index: word for word, word_index in self.vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        splitText = re.findall(r'\\w+|[,.:;?_!\"()\\']|--', text)\n",
    "        IDs = [self.vocab[token] for token in splitText]\n",
    "        return IDs\n",
    "    def decode(self, IDs):\n",
    "        text = \" \".join([self.inverseVocab[ID] for ID in IDs])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 867, 1006, 615, 546, 760, 5, 1144, 609, 5, 1, 67, 7, 38, 868, 1126, 769, 810, 7]\n",
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)\n",
    "decText = tokenizer.decode(ids)\n",
    "print(decText)\n",
    "# There is one problem with this, there is an extra space after all the \" and ' which is not accurate to the original text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed', 'Devonshire', 'Don', 'Dubarry_', 'Emperors', 'Florence', 'For', 'Gallery', 'Gideon', 'Gisburn', 'Gisburns', 'Grafton', 'Greek', 'Grindle', 'Grindles', 'HAD', 'Had', 'Hang', 'Has', 'He', 'Her', 'Hermia', 'His', 'How', 'I', 'If', 'In', 'It', 'Jack', 'Jove', 'Just', 'Lord', 'Made', 'Miss', 'Money', 'Monte', 'Moon', 'Mr', 'Mrs', 'My', 'Never', 'No', 'Now', 'Nutley', 'Of', 'Oh', 'On', 'Once', 'Only', 'Or', 'Perhaps', 'Poor', 'Professional', 'Renaissance', 'Rickham', 'Riviera', 'Rome', 'Russian', 'Sevres', 'She', 'Stroud', 'Strouds', 'Suddenly', 'That', 'The', 'Then', 'There', 'They', 'This', 'Those', 'Though', 'Thwing', 'Thwings', 'To', 'Usually', 'Venetian', 'Victor', 'Was', 'We', 'Well', 'What', 'When', 'Why', 'Yes', 'You', '_I', '_am_', '_famille', '_felt_', '_has_', '_have_', '_jardiniere_', '_mine_', '_not_', '_rose', '_rs_', '_that_', '_the_', '_was_', '_were_', 'a', 'abdication', 'able', 'about', 'above', 'abruptly', 'absolute', 'absorbed', 'absurdity', 'academic', 'accuse', 'accustomed', 'across', 'activity', 'add', 'added', 'admirers', 'adopted', 'adulation', 'advance', 'aesthetic', 'affect', 'afraid', 'after', 'afterward', 'again', 'ago', 'ah', 'air', 'alive', 'all', 'almost', 'alone', 'along', 'always', 'amazement', 'amid', 'among', 'amplest', 'amusing', 'an', 'and', 'another', 'answer', 'answered', 'any', 'anything', 'anywhere', 'apparent', 'apparently', 'appearance', 'appeared', 'appointed', 'are', 'arm', 'arms', 'art', 'articles', 'artist', 'as', 'aside', 'asked', 'at', 'atmosphere', 'atom', 'attack', 'attention', 'attitude', 'audacities', 'away', 'awful', 'axioms', 'azaleas', 'back', 'background', 'balance', 'balancing', 'balustraded', 'basking', 'bath', 'be', 'beaming', 'bean', 'bear', 'beard', 'beauty', 'became', 'because', 'becoming', 'bed', 'been', 'before', 'began', 'begun', 'behind', 'being', 'believed', 'beneath', 'bespoke', 'better', 'between', 'big', 'bits', 'bitterness', 'blocked', 'born', 'borne', 'boudoir', 'brac', 'bravura', 'break', 'breaking', 'breathing', 'breeding', 'bric', 'briefly', 'brings', 'bronzes', 'brought', 'brown', 'brush', 'bull', 'business', 'but', 'buying', 'by', 'called', 'came', 'can', 'canvas', 'canvases', 'cards', 'care', 'career', 'caught', 'central', 'century', 'chair', 'chairs', 'chap', 'characteristic', 'charming', 'cheap', 'check', 'cheeks', 'chest', 'chimney', 'chucked', 'cigar', 'cigarette', 'cigars', 'circulation', 'circumstance', 'circus', 'claimed', 'clasping', 'clear', 'cleverer', 'close', 'closets', 'clown', 'clue', 'coat', 'collapsed', 'colour', 'come', 'comfortable', 'coming', 'companion', 'compared', 'complex', 'confident', 'congesting', 'conjugal', 'constraint', 'consummate', 'contended', 'continued', 'corner', 'corrected', 'cotta', 'could', 'couldn', 'count', 'countenance', 'couple', 'course', 'covered', 'craft', 'cried', 'crossed', 'crowned', 'crumbled', 'cry', 'cured', 'curiosity', 'curious', 'current', 'curtains', 'd', 'dabble', 'damask', 'dancers', 'dark', 'dashed', 'day', 'days', 'dead', 'deadening', 'dear', 'deep', 'deerhound', 'degree', 'delicate', 'demand', 'denied', 'deploring', 'deprecating', 'deprecatingly', 'desire', 'destroyed', 'destruction', 'desultory', 'detail', 'diagnosis', 'did', 'didn', 'died', 'dim', 'dimmest', 'dingy', 'dining', 'disarming', 'discovery', 'discrimination', 'discussion', 'disdain', 'disdained', 'disease', 'disguised', 'display', 'dissatisfied', 'distinguished', 'distract', 'divert', 'do', 'doesn', 'doing', 'domestic', 'don', 'done', 'donkey', 'down', 'dozen', 'dragged', 'drawing', 'drawn', 'dress', 'drew', 'dropped', 'each', 'earth', 'ease', 'easel', 'easy', 'echoed', 'economy', 'effect', 'effects', 'efforts', 'egregious', 'eighteenth', 'elbow', 'elegant', 'else', 'embarrassed', 'enabled', 'end', 'endless', 'enjoy', 'enlightenment', 'enough', 'ensuing', 'equally', 'equanimity', 'escape', 'established', 'etching', 'even', 'event', 'ever', 'everlasting', 'every', 'exasperated', 'except', 'excuse', 'excusing', 'existed', 'expected', 'exquisite', 'exquisitely', 'extenuation', 'exterminating', 'extracting', 'eye', 'eyebrows', 'eyes', 'face', 'faces', 'fact', 'faded', 'failed', 'failure', 'fair', 'faith', 'false', 'familiar', 'fancy', 'fashionable', 'fate', 'feather', 'feet', 'fell', 'fellow', 'felt', 'few', 'fewer', 'finality', 'find', 'fingers', 'first', 'fit', 'fitting', 'five', 'flash', 'flashed', 'florid', 'flowers', 'fluently', 'flung', 'follow', 'followed', 'fond', 'footstep', 'for', 'forced', 'forcing', 'forehead', 'foreign', 'foreseen', 'forgive', 'forgotten', 'form', 'formed', 'forming', 'forward', 'fostered', 'found', 'foundations', 'four', 'fragment', 'fragments', 'frame', 'frames', 'frequently', 'friend', 'from', 'full', 'fullest', 'furiously', 'furrowed', 'garlanded', 'garlands', 'gave', 'genial', 'genius', 'gesture', 'get', 'getting', 'give', 'given', 'glad', 'glanced', 'glimpse', 'gloried', 'glory', 'go', 'going', 'gone', 'good', 'got', 'grace', 'gradually', 'gray', 'grayish', 'great', 'greatest', 'greatness', 'grew', 'groping', 'growing', 'had', 'hadn', 'hair', 'half', 'hall', 'hand', 'hands', 'handsome', 'hanging', 'happen', 'happened', 'hard', 'hardly', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'height', 'her', 'here', 'hermit', 'herself', 'hesitations', 'hide', 'high', 'him', 'himself', 'hint', 'his', 'history', 'holding', 'home', 'honour', 'hooded', 'hostess', 'hot', 'hour', 'hours', 'house', 'how', 'humoured', 'hung', 'husband', 'idea', 'idle', 'idling', 'if', 'immediately', 'in', 'incense', 'indifferent', 'inevitable', 'inevitably', 'inflexible', 'insensible', 'insignificant', 'instinctively', 'instructive', 'interesting', 'into', 'ironic', 'irony', 'irrelevance', 'irrevocable', 'is', 'it', 'its', 'itself', 'jealousy', 'just', 'keep', 'kept', 'kind', 'knees', 'knew', 'know', 'known_', 'laid', 'lair', 'landing', 'language', 'last', 'late', 'later', 'latter', 'laugh', 'laughed', 'lay', 'leading', 'lean', 'learned', 'least', 'leathery', 'leave', 'led', 'left', 'leisure', 'lends', 'lent', 'let', 'lies', 'life', 'lift', 'lifted', 'light', 'lightly', 'like', 'liked', 'likeness', 'line', 'lines', 'lingered', 'lips', 'lit', 'little', 'live', 'll', 'loathing', 'long', 'longed', 'longer', 'look', 'looked', 'looking', 'lose', 'loss', 'lounging', 'lovely', 'lucky', 'lump', 'luncheon', 'luxury', 'lying', 'made', 'make', 'man', 'manage', 'managed', 'mantel', 'marble', 'married', 'may', 'me', 'meant', 'mechanically', 'mediocrity', 'medium', 'mentioned', 'mere', 'merely', 'met', 'might', 'mighty', 'millionaire', 'mine', 'minute', 'minutes', 'mirrors', 'modest', 'modesty', 'moment', 'money', 'monumental', 'mood', 'morbidly', 'more', 'most', 'mourn', 'mourned', 'moustache', 'moved', 'much', 'muddling', 'multiplied', 'murmur', 'muscles', 'must', 'my', 'myself', 'mysterious', 'naive', 'near', 'nearly', 'negatived', 'nervous', 'nervousness', 'neutral', 'never', 'next', 'no', 'none', 'not', 'note', 'nothing', 'now', 'nymphs', 'oak', 'obituary', 'object', 'objects', 'occurred', 'oddly', 'of', 'off', 'often', 'oh', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'open', 'or', 'other', 'our', 'ourselves', 'out', 'outline', 'oval', 'over', 'own', 'packed', 'paid', 'paint', 'painted', 'painter', 'painting', 'pale', 'paled', 'palm', 'panel', 'panelled', 'panelling', 'pardonable', 'pardoned', 'part', 'passages', 'passing', 'past', 'pastels', 'pathos', 'patient', 'people', 'perceptible', 'perfect', 'persistence', 'persuasively', 'phrase', 'picture', 'pictures', 'piece', 'pines', 'pink', 'place', 'placed', 'plain', 'platitudes', 'pleased', 'pockets', 'point', 'poised', 'poor', 'portrait', 'posing', 'possessed', 'poverty', 'predicted', 'preliminary', 'presenting', 'presses', 'prestidigitation', 'pretty', 'previous', 'price', 'pride', 'princely', 'prism', 'problem', 'proclaiming', 'prodigious', 'profusion', 'protest', 'prove', 'public', 'purblind', 'purely', 'pushed', 'put', 'qualities', 'quality', 'queerly', 'question', 'quickly', 'quietly', 'quite', 'quote', 'rain', 'raised', 'random', 'rather', 're', 'real', 'really', 'reared', 'reason', 'reassurance', 'recovering', 'recreated', 'reflected', 'reflection', 'regrets', 'relatively', 'remained', 'remember', 'reminded', 'repeating', 'represented', 'reproduction', 'resented', 'resolve', 'resources', 'rest', 'rich', 'ridiculous', 'robbed', 'romantic', 'room', 'rooms', 'rose', 'rule', 'run', 's', 'said', 'same', 'satisfaction', 'savour', 'saw', 'say', 'saying', 'says', 'scorn', 'scornful', 'secret', 'see', 'seemed', 'seen', 'self', 'send', 'sensation', 'sensitive', 'sent', 'serious', 'set', 'sex', 'shade', 'shaking', 'shall', 'she', 'shirked', 'short', 'should', 'shoulder', 'shoulders', 'show', 'showed', 'showy', 'shrug', 'shrugged', 'sight', 'sign', 'silent', 'silver', 'similar', 'simpleton', 'simplifications', 'simply', 'since', 'single', 'sitter', 'sitters', 'sketch', 'skill', 'slight', 'slightly', 'slowly', 'small', 'smile', 'smiling', 'sneer', 'so', 'solace', 'some', 'somebody', 'something', 'spacious', 'spaniel', 'speaking', 'speculations', 'spite', 'splash', 'square', 'stairs', 'stalk', 'stammer', 'stand', 'standing', 'started', 'stay', 'still', 'stocked', 'stood', 'stopped', 'stopping', 'straddling', 'straight', 'strain', 'straining', 'strange', 'straw', 'stream', 'stroke', 'strokes', 'strolled', 'strongest', 'strongly', 'struck', 'studio', 'stuff', 'subject', 'substantial', 'suburban', 'such', 'suddenly', 'suffered', 'sugar', 'suggested', 'sunburn', 'sunburnt', 'sunlit', 'superb', 'sure', 'surest', 'surface', 'surprise', 'surprised', 'surrounded', 'suspected', 'sweetly', 'sweetness', 'swelling', 'swept', 'swum', 't', 'table', 'take', 'taken', 'talking', 'tea', 'tears', 'technicalities', 'technique', 'tell', 'tells', 'tempting', 'terra', 'terrace', 'terraces', 'terribly', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'they', 'thin', 'thing', 'things', 'think', 'this', 'thither', 'those', 'though', 'thought', 'three', 'threshold', 'threw', 'through', 'throwing', 'tie', 'till', 'time', 'timorously', 'tinge', 'tips', 'tired', 'to', 'told', 'tone', 'tones', 'too', 'took', 'tottering', 'touched', 'toward', 'trace', 'trade', 'transmute', 'traps', 'travelled', 'trees', 'tribute', 'tributes', 'tricks', 'tried', 'trouser', 'true', 'truth', 'tubes', 'turned', 'twenty', 'twice', 'twirling', 'unaccountable', 'uncertain', 'under', 'underlay', 'underneath', 'understand', 'unexpected', 'untouched', 'unusual', 'up', 'upon', 'upset', 'upstairs', 'us', 'used', 'usual', 'value', 'varnishing', 'vases', 've', 'veins', 'velveteen', 'verte_', 'very', 'villa', 'vindicated', 'virtuosity', 'vista', 'vocation', 'voice', 'wall', 'wander', 'want', 'wanted', 'wants', 'was', 'wasn', 'watched', 'watching', 'water', 'waves', 'way', 'weekly', 'weeks', 'welcome', 'went', 'were', 'what', 'when', 'whenever', 'where', 'which', 'while', 'white', 'who', 'whole', 'whom', 'why', 'wide', 'widow', 'wife', 'wild', 'wincing', 'window', 'wish', 'with', 'without', 'wits', 'woman', 'women', 'won', 'wonder', 'wondered', 'word', 'work', 'working', 'worth', 'would', 'wouldn', 'year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself']\n",
      "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed', 'Devonshire', 'Don', 'Dubarry_', 'Emperors', 'Florence', 'For', 'Gallery', 'Gideon', 'Gisburn', 'Gisburns', 'Grafton', 'Greek', 'Grindle', 'Grindles', 'HAD', 'Had', 'Hang', 'Has', 'He', 'Her', 'Hermia', 'His', 'How', 'I', 'If', 'In', 'It', 'Jack', 'Jove', 'Just', 'Lord', 'Made', 'Miss', 'Money', 'Monte', 'Moon', 'Mr', 'Mrs', 'My', 'Never', 'No', 'Now', 'Nutley', 'Of', 'Oh', 'On', 'Once', 'Only', 'Or', 'Perhaps', 'Poor', 'Professional', 'Renaissance', 'Rickham', 'Riviera', 'Rome', 'Russian', 'Sevres', 'She', 'Stroud', 'Strouds', 'Suddenly', 'That', 'The', 'Then', 'There', 'They', 'This', 'Those', 'Though', 'Thwing', 'Thwings', 'To', 'Usually', 'Venetian', 'Victor', 'Was', 'We', 'Well', 'What', 'When', 'Why', 'Yes', 'You', '_I', '_am_', '_famille', '_felt_', '_has_', '_have_', '_jardiniere_', '_mine_', '_not_', '_rose', '_rs_', '_that_', '_the_', '_was_', '_were_', 'a', 'abdication', 'able', 'about', 'above', 'abruptly', 'absolute', 'absorbed', 'absurdity', 'academic', 'accuse', 'accustomed', 'across', 'activity', 'add', 'added', 'admirers', 'adopted', 'adulation', 'advance', 'aesthetic', 'affect', 'afraid', 'after', 'afterward', 'again', 'ago', 'ah', 'air', 'alive', 'all', 'almost', 'alone', 'along', 'always', 'amazement', 'amid', 'among', 'amplest', 'amusing', 'an', 'and', 'another', 'answer', 'answered', 'any', 'anything', 'anywhere', 'apparent', 'apparently', 'appearance', 'appeared', 'appointed', 'are', 'arm', 'arms', 'art', 'articles', 'artist', 'as', 'aside', 'asked', 'at', 'atmosphere', 'atom', 'attack', 'attention', 'attitude', 'audacities', 'away', 'awful', 'axioms', 'azaleas', 'back', 'background', 'balance', 'balancing', 'balustraded', 'basking', 'bath', 'be', 'beaming', 'bean', 'bear', 'beard', 'beauty', 'became', 'because', 'becoming', 'bed', 'been', 'before', 'began', 'begun', 'behind', 'being', 'believed', 'beneath', 'bespoke', 'better', 'between', 'big', 'bits', 'bitterness', 'blocked', 'born', 'borne', 'boudoir', 'brac', 'bravura', 'break', 'breaking', 'breathing', 'breeding', 'bric', 'briefly', 'brings', 'bronzes', 'brought', 'brown', 'brush', 'bull', 'business', 'but', 'buying', 'by', 'called', 'came', 'can', 'canvas', 'canvases', 'cards', 'care', 'career', 'caught', 'central', 'century', 'chair', 'chairs', 'chap', 'characteristic', 'charming', 'cheap', 'check', 'cheeks', 'chest', 'chimney', 'chucked', 'cigar', 'cigarette', 'cigars', 'circulation', 'circumstance', 'circus', 'claimed', 'clasping', 'clear', 'cleverer', 'close', 'closets', 'clown', 'clue', 'coat', 'collapsed', 'colour', 'come', 'comfortable', 'coming', 'companion', 'compared', 'complex', 'confident', 'congesting', 'conjugal', 'constraint', 'consummate', 'contended', 'continued', 'corner', 'corrected', 'cotta', 'could', 'couldn', 'count', 'countenance', 'couple', 'course', 'covered', 'craft', 'cried', 'crossed', 'crowned', 'crumbled', 'cry', 'cured', 'curiosity', 'curious', 'current', 'curtains', 'd', 'dabble', 'damask', 'dancers', 'dark', 'dashed', 'day', 'days', 'dead', 'deadening', 'dear', 'deep', 'deerhound', 'degree', 'delicate', 'demand', 'denied', 'deploring', 'deprecating', 'deprecatingly', 'desire', 'destroyed', 'destruction', 'desultory', 'detail', 'diagnosis', 'did', 'didn', 'died', 'dim', 'dimmest', 'dingy', 'dining', 'disarming', 'discovery', 'discrimination', 'discussion', 'disdain', 'disdained', 'disease', 'disguised', 'display', 'dissatisfied', 'distinguished', 'distract', 'divert', 'do', 'doesn', 'doing', 'domestic', 'don', 'done', 'donkey', 'down', 'dozen', 'dragged', 'drawing', 'drawn', 'dress', 'drew', 'dropped', 'each', 'earth', 'ease', 'easel', 'easy', 'echoed', 'economy', 'effect', 'effects', 'efforts', 'egregious', 'eighteenth', 'elbow', 'elegant', 'else', 'embarrassed', 'enabled', 'end', 'endless', 'enjoy', 'enlightenment', 'enough', 'ensuing', 'equally', 'equanimity', 'escape', 'established', 'etching', 'even', 'event', 'ever', 'everlasting', 'every', 'exasperated', 'except', 'excuse', 'excusing', 'existed', 'expected', 'exquisite', 'exquisitely', 'extenuation', 'exterminating', 'extracting', 'eye', 'eyebrows', 'eyes', 'face', 'faces', 'fact', 'faded', 'failed', 'failure', 'fair', 'faith', 'false', 'familiar', 'fancy', 'fashionable', 'fate', 'feather', 'feet', 'fell', 'fellow', 'felt', 'few', 'fewer', 'finality', 'find', 'fingers', 'first', 'fit', 'fitting', 'five', 'flash', 'flashed', 'florid', 'flowers', 'fluently', 'flung', 'follow', 'followed', 'fond', 'footstep', 'for', 'forced', 'forcing', 'forehead', 'foreign', 'foreseen', 'forgive', 'forgotten', 'form', 'formed', 'forming', 'forward', 'fostered', 'found', 'foundations', 'four', 'fragment', 'fragments', 'frame', 'frames', 'frequently', 'friend', 'from', 'full', 'fullest', 'furiously', 'furrowed', 'garlanded', 'garlands', 'gave', 'genial', 'genius', 'gesture', 'get', 'getting', 'give', 'given', 'glad', 'glanced', 'glimpse', 'gloried', 'glory', 'go', 'going', 'gone', 'good', 'got', 'grace', 'gradually', 'gray', 'grayish', 'great', 'greatest', 'greatness', 'grew', 'groping', 'growing', 'had', 'hadn', 'hair', 'half', 'hall', 'hand', 'hands', 'handsome', 'hanging', 'happen', 'happened', 'hard', 'hardly', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'height', 'her', 'here', 'hermit', 'herself', 'hesitations', 'hide', 'high', 'him', 'himself', 'hint', 'his', 'history', 'holding', 'home', 'honour', 'hooded', 'hostess', 'hot', 'hour', 'hours', 'house', 'how', 'humoured', 'hung', 'husband', 'idea', 'idle', 'idling', 'if', 'immediately', 'in', 'incense', 'indifferent', 'inevitable', 'inevitably', 'inflexible', 'insensible', 'insignificant', 'instinctively', 'instructive', 'interesting', 'into', 'ironic', 'irony', 'irrelevance', 'irrevocable', 'is', 'it', 'its', 'itself', 'jealousy', 'just', 'keep', 'kept', 'kind', 'knees', 'knew', 'know', 'known_', 'laid', 'lair', 'landing', 'language', 'last', 'late', 'later', 'latter', 'laugh', 'laughed', 'lay', 'leading', 'lean', 'learned', 'least', 'leathery', 'leave', 'led', 'left', 'leisure', 'lends', 'lent', 'let', 'lies', 'life', 'lift', 'lifted', 'light', 'lightly', 'like', 'liked', 'likeness', 'line', 'lines', 'lingered', 'lips', 'lit', 'little', 'live', 'll', 'loathing', 'long', 'longed', 'longer', 'look', 'looked', 'looking', 'lose', 'loss', 'lounging', 'lovely', 'lucky', 'lump', 'luncheon', 'luxury', 'lying', 'made', 'make', 'man', 'manage', 'managed', 'mantel', 'marble', 'married', 'may', 'me', 'meant', 'mechanically', 'mediocrity', 'medium', 'mentioned', 'mere', 'merely', 'met', 'might', 'mighty', 'millionaire', 'mine', 'minute', 'minutes', 'mirrors', 'modest', 'modesty', 'moment', 'money', 'monumental', 'mood', 'morbidly', 'more', 'most', 'mourn', 'mourned', 'moustache', 'moved', 'much', 'muddling', 'multiplied', 'murmur', 'muscles', 'must', 'my', 'myself', 'mysterious', 'naive', 'near', 'nearly', 'negatived', 'nervous', 'nervousness', 'neutral', 'never', 'next', 'no', 'none', 'not', 'note', 'nothing', 'now', 'nymphs', 'oak', 'obituary', 'object', 'objects', 'occurred', 'oddly', 'of', 'off', 'often', 'oh', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'open', 'or', 'other', 'our', 'ourselves', 'out', 'outline', 'oval', 'over', 'own', 'packed', 'paid', 'paint', 'painted', 'painter', 'painting', 'pale', 'paled', 'palm', 'panel', 'panelled', 'panelling', 'pardonable', 'pardoned', 'part', 'passages', 'passing', 'past', 'pastels', 'pathos', 'patient', 'people', 'perceptible', 'perfect', 'persistence', 'persuasively', 'phrase', 'picture', 'pictures', 'piece', 'pines', 'pink', 'place', 'placed', 'plain', 'platitudes', 'pleased', 'pockets', 'point', 'poised', 'poor', 'portrait', 'posing', 'possessed', 'poverty', 'predicted', 'preliminary', 'presenting', 'presses', 'prestidigitation', 'pretty', 'previous', 'price', 'pride', 'princely', 'prism', 'problem', 'proclaiming', 'prodigious', 'profusion', 'protest', 'prove', 'public', 'purblind', 'purely', 'pushed', 'put', 'qualities', 'quality', 'queerly', 'question', 'quickly', 'quietly', 'quite', 'quote', 'rain', 'raised', 'random', 'rather', 're', 'real', 'really', 'reared', 'reason', 'reassurance', 'recovering', 'recreated', 'reflected', 'reflection', 'regrets', 'relatively', 'remained', 'remember', 'reminded', 'repeating', 'represented', 'reproduction', 'resented', 'resolve', 'resources', 'rest', 'rich', 'ridiculous', 'robbed', 'romantic', 'room', 'rooms', 'rose', 'rule', 'run', 's', 'said', 'same', 'satisfaction', 'savour', 'saw', 'say', 'saying', 'says', 'scorn', 'scornful', 'secret', 'see', 'seemed', 'seen', 'self', 'send', 'sensation', 'sensitive', 'sent', 'serious', 'set', 'sex', 'shade', 'shaking', 'shall', 'she', 'shirked', 'short', 'should', 'shoulder', 'shoulders', 'show', 'showed', 'showy', 'shrug', 'shrugged', 'sight', 'sign', 'silent', 'silver', 'similar', 'simpleton', 'simplifications', 'simply', 'since', 'single', 'sitter', 'sitters', 'sketch', 'skill', 'slight', 'slightly', 'slowly', 'small', 'smile', 'smiling', 'sneer', 'so', 'solace', 'some', 'somebody', 'something', 'spacious', 'spaniel', 'speaking', 'speculations', 'spite', 'splash', 'square', 'stairs', 'stalk', 'stammer', 'stand', 'standing', 'started', 'stay', 'still', 'stocked', 'stood', 'stopped', 'stopping', 'straddling', 'straight', 'strain', 'straining', 'strange', 'straw', 'stream', 'stroke', 'strokes', 'strolled', 'strongest', 'strongly', 'struck', 'studio', 'stuff', 'subject', 'substantial', 'suburban', 'such', 'suddenly', 'suffered', 'sugar', 'suggested', 'sunburn', 'sunburnt', 'sunlit', 'superb', 'sure', 'surest', 'surface', 'surprise', 'surprised', 'surrounded', 'suspected', 'sweetly', 'sweetness', 'swelling', 'swept', 'swum', 't', 'table', 'take', 'taken', 'talking', 'tea', 'tears', 'technicalities', 'technique', 'tell', 'tells', 'tempting', 'terra', 'terrace', 'terraces', 'terribly', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'they', 'thin', 'thing', 'things', 'think', 'this', 'thither', 'those', 'though', 'thought', 'three', 'threshold', 'threw', 'through', 'throwing', 'tie', 'till', 'time', 'timorously', 'tinge', 'tips', 'tired', 'to', 'told', 'tone', 'tones', 'too', 'took', 'tottering', 'touched', 'toward', 'trace', 'trade', 'transmute', 'traps', 'travelled', 'trees', 'tribute', 'tributes', 'tricks', 'tried', 'trouser', 'true', 'truth', 'tubes', 'turned', 'twenty', 'twice', 'twirling', 'unaccountable', 'uncertain', 'under', 'underlay', 'underneath', 'understand', 'unexpected', 'untouched', 'unusual', 'up', 'upon', 'upset', 'upstairs', 'us', 'used', 'usual', 'value', 'varnishing', 'vases', 've', 'veins', 'velveteen', 'verte_', 'very', 'villa', 'vindicated', 'virtuosity', 'vista', 'vocation', 'voice', 'wall', 'wander', 'want', 'wanted', 'wants', 'was', 'wasn', 'watched', 'watching', 'water', 'waves', 'way', 'weekly', 'weeks', 'welcome', 'went', 'were', 'what', 'when', 'whenever', 'where', 'which', 'while', 'white', 'who', 'whole', 'whom', 'why', 'wide', 'widow', 'wife', 'wild', 'wincing', 'window', 'wish', 'with', 'without', 'wits', 'woman', 'women', 'won', 'wonder', 'wondered', 'word', 'work', 'working', 'worth', 'would', 'wouldn', 'year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself', '<|endoftext|>', '<|unk|>']\n",
      "1150\n"
     ]
    }
   ],
   "source": [
    "#2.4\n",
    "print(allWords)\n",
    "allWords.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "print(allWords)\n",
    "vocab = {token: index for index,token in enumerate(allWords)}\n",
    "print(len(vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.inverseVocab = {word_index: word for word, word_index in self.vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        splitText = re.findall(r'<\\|[^|]+\\|>|\"\\s*<\\|[^|]+\\|>\"|[a-zA-Z0-9]+|[,.:;?_!\"()\\']|--|\"', text)\n",
    "        IDs = [self.vocab[token] if token in self.vocab.keys() else self.vocab[\"<|unk|>\"] for token in splitText]\n",
    "        return IDs\n",
    "    def decode(self, IDs):\n",
    "        text = \" \".join([self.inverseVocab[ID] for ID in IDs])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1149, 5, 374, 1144, 640, 993, 10, 1148, 55, 1006, 974, 1002, 736, 1006, 1149, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "tokenizer2 = SimpleTokenizerV2(vocab)\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "ids = tokenizer2.encode(text)\n",
    "print(ids)\n",
    "decText = tokenizer2.decode(ids)\n",
    "print(decText)\n",
    "# There is one problem with this, there is an extra space after all the \" and ' which is not accurate to the original text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 BPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n",
      "[b'Hello', b',', b' do', b' you', b' like', b' tea', b'?', b' ', b'<|endoftext|>', b' In', b' the', b' sun', b'lit', b' terr', b'aces', b' of', b' some', b'unknown', b'Place', b'.']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)\n",
    "token_words = [tokenizer.decode_single_token_bytes(token) for token in integers]\n",
    "print(token_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "with open(\"TheVerdict.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y: \t[4920, 2241, 287, 257]\n",
      " and -->  established\n",
      " and established -->  himself\n",
      " and established himself -->  in\n",
      " and established himself in -->  a\n"
     ]
    }
   ],
   "source": [
    "enc_sample = enc_text[50:]\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1: context_size+1]\n",
    "print(f\"x: {x}\\ny: \\t{y}\")\n",
    "\n",
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f\"{tokenizer.decode(context)} --> {tokenizer.decode([desired])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_len, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids)-max_len, stride):\n",
    "            x = token_ids[i: i+max_len]\n",
    "            y = token_ids[i+1: i+max_len+1]\n",
    "            self.input_ids.append(torch.tensor(x))\n",
    "            self.target_ids.append(torch.tensor(y))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n",
    "    \n",
    "\n",
    "def create_dataloader_v1(txt: str, batch_size=4, max_len=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_len, stride)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=num_workers,\n",
    "                            drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464],\n",
      "        [ 367, 2885, 1464, 1807],\n",
      "        [2885, 1464, 1807, 3619]]), tensor([[ 367, 2885, 1464, 1807],\n",
      "        [2885, 1464, 1807, 3619],\n",
      "        [1464, 1807, 3619,  402]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"TheVerdict.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    txt = f.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(txt, batch_size=3, max_len=4, stride=1, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "embedding_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.Tensor([3]).int())) # this is just the index 3 ele in the above matrix\n",
    "# torch.Tensor([3]).int() same as torch.tensor([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [-2.8400, -0.7849, -1.4096]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([2,4,1,5])\n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims: 160 x 8 x 4\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "embedding_dim = 256\n",
    "token_embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(txt, batch_size=8, max_len=max_length, stride=max_length, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "# print(inputs)\n",
    "# print(targets)\n",
    "print(f\"dims: {len(dataloader)} x {inputs.shape[0]} x {inputs.shape[1]}\")\n",
    "\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7180, -1.6009,  0.3609,  ..., -2.2394, -1.4581, -0.8744],\n",
      "        [ 1.5543, -2.1174,  0.4044,  ..., -1.3120, -0.6699,  1.2716],\n",
      "        [-0.6629,  0.4562,  0.0575,  ...,  0.0279, -1.0018,  0.4836],\n",
      "        [ 0.3225, -1.1543,  1.6842,  ..., -0.3874,  1.1326, -1.7115]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "# For a GPT models absolute embedding approach, we just need to create another embedding layer that has the same embedding dimension as the token_embedding_layer\n",
    "\n",
    "context_length = max_length\n",
    "pos_embedding_layer = nn.Embedding(context_length, embedding_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings, pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4466, -1.2089,  1.9116,  ..., -2.5171,  0.5177,  1.0508],\n",
      "         [ 2.3725, -2.1144,  0.2816,  ..., -0.2947,  0.7927,  1.1478],\n",
      "         [ 0.7618,  2.3193, -0.8711,  ...,  1.4673,  0.3900,  1.9076],\n",
      "         [-0.2153,  2.6686,  2.2753,  ..., -0.6694,  0.0707, -0.6766]],\n",
      "\n",
      "        [[ 0.4577, -1.1822,  1.7659,  ..., -4.6932, -0.5067, -0.9455],\n",
      "         [ 0.1795, -3.4956,  0.5759,  ..., -2.8583, -0.7475,  0.1249],\n",
      "         [-1.7056, -0.2779, -0.8310,  ...,  0.1600,  0.0992, -0.8924],\n",
      "         [-0.0237, -1.3716,  0.8419,  ..., -1.3682,  0.8221, -4.5292]],\n",
      "\n",
      "        [[-0.6946, -2.2963,  0.3489,  ..., -0.2686, -1.4820, -0.8296],\n",
      "         [ 2.2095, -1.5307,  0.2493,  ..., -2.4683, -0.1960,  0.5276],\n",
      "         [-1.9803,  1.2496,  0.2502,  ..., -0.2331, -3.1653, -0.4573],\n",
      "         [ 0.7768, -2.5170,  1.2508,  ..., -0.2933,  0.6892, -2.6618]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5846, -2.6068, -0.6915,  ..., -2.2684, -0.4264, -1.8845],\n",
      "         [ 1.2949, -3.3428, -0.5533,  ..., -0.7721, -0.5160,  0.0515],\n",
      "         [ 0.2280, -0.8396, -0.8805,  ..., -0.4990, -2.1024,  0.4730],\n",
      "         [ 1.7845, -1.0201,  0.8321,  ...,  0.4270,  0.7995, -2.9071]],\n",
      "\n",
      "        [[-1.3920, -1.1012, -0.8087,  ..., -2.2280,  0.1829,  0.7288],\n",
      "         [ 0.8957, -3.0011, -0.1952,  ..., -2.2811, -0.1813, -0.2016],\n",
      "         [-1.6125,  1.6080,  1.8580,  ..., -0.7589, -1.7453, -0.6505],\n",
      "         [ 1.3073, -1.2543,  1.9320,  ..., -0.8417,  1.4258, -2.9779]],\n",
      "\n",
      "        [[-1.6676, -0.4491,  2.1614,  ..., -3.0262, -2.2017, -2.0085],\n",
      "         [ 3.4772, -2.0702,  1.3927,  ..., -2.2719, -1.1254,  1.3713],\n",
      "         [-0.7608,  0.4116, -1.3684,  ..., -0.3602, -1.9077,  0.0068],\n",
      "         [ 0.1040, -1.8625,  1.6806,  ...,  0.9937,  3.0857, -2.7207]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings, input_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
